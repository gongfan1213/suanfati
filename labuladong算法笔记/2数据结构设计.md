# 2.2 数据结构设计

哈希表能够提供O(1)的键值对存取操作，经常用来给其他的数据结构添加超能力，
### 2.2.1LRU算法

Least Recently Used

当然还有其他的缓存淘汰策略，比如不要按照访问的时序来淘汰，而是按照访问的频率LRU策略来淘汰等等各有应用场景的，

## 1.LRU算法，

首先要接受一个capacity参数作为缓存的最大容量，然后实现两个API，一个是put(key, val)方法存入键值对，另一个是get(key)方法获取key对应的val，如果key不存在则返回-1。

注意哦，get和put方法必须都是O(1)的时间复杂度，我们举个具体例子来看看LRU算法怎么工作。

```java
/* 缓存容量为 2 */
LRUCache cache = new LRUCache(2);
// 你可以把 cache 理解成一个队列
// 假设左边是队头，右边是队尾
// 最近使用的排在队头，久未使用的排在队尾
// 圆括号表示键值对 (key, val)

cache.put(1, 1);
// cache = [(1, 1)]
cache.put(2, 2);
// cache = [(2, 2), (1, 1)]
cache.get(1);       // 返回 1
// cache = [(1, 1), (2, 2)]
// 解释：因为最近访问了键 1，所以提前至队头
// 返回键 1 对应的值 1
cache.put(3, 3);
//解释缓存容量已经满了，需要删除内容空出位置，
//优先删除久未使用的数据，也就是队尾的数据
//然后把新的数据插入队头
cache.get(2);       // 返回 -1 (未找到
// cache = [(3, 3), (1, 1)]
// 解释：cache 中不存在键为 2 的数据
cache.put(1, 4);
// cache = [(1, 4), (3, 3)]
// 解释：键 1 已存在，把原始值 1 覆盖为 4
// 不要忘了也要将键值对提前到队头
```
# 2.LRU算法设计

分析上面的操作过程。要让put和get方法的时间复杂度为O(1)，我们可以总结出cache这个数据结构必要的条件：查找快，插入快，删除快，有顺序之分。

因为显然cache中的数据必须有时序，以区分最近使用的和久未使用的数据，当容量满了之后要删除最久未使用的那个元素腾位置。

要在cache中快速找某个key是否存在并得到对应的val；

每次访问cache中的某个key，需要将这个元素变为最近使用的，也就是说cache要支持在任意位置快速插入和删除元素。

那么，什么1数据结构同时符合上述条件呢？哈希奥查找快，但是数据无固定顺序；链表有顺序之分，插入删除快，但是查找慢。所以结合一下，形成一种新的数据结构：哈希链表。

LRU 缓存算法的核心数据结构就是哈希链表，双向链表和哈希表的结合体。这个数据结构长这样：

LRU核心算法数据结构是哈希链表，双向链表和哈希表的结合体

借助这个结构，我们来逐一分析上面的 3 个条件：

1、如果我们每次默认从链表尾部添加元素，那么显然越靠尾部的元素就是最近使用的，越靠头部的元素就是最久未使用的。

2、对于某一个key，我们可以通过哈希表快速定位到链表中的节点，从而取得对应val。

3、链表显然是支持在任意位置快速插入和删除的，改改指针就行。只不过传统的链表无法按照索引快速访问某一个位置的元素，而这里借助哈希表，可以通过key快速映射到任意一个链表节点，然后进行插入和删除。

也许读者会问，为什么要是双向链表，单链表行不行？另外，既然哈希表中已经存了key，为什么链表中还要存键值对呢，只存值不就行了？

想的时候都是问题，只有做的时候才有答案，这样设计的原因，必须等我们亲自实现LRU算法，之后才能理解的，所以我们开始看代码吧

# 三。代码实现

很多编程语言都有内置的哈希链表或者类似 LRU 功能的库函数，但是为了帮大家理解算法的细节，我们先自己造轮子实现一遍 LRU 算法，然后再使用 Java 内置的 LinkedHashMap 来实现一遍。

首先，我们把双链表的节点类写出来，为了简化，key和val都认为是int类型：

```java
class Node{
    public int key, val;
    public Node next, prev;
    public Node(int k, int v) {
        this.key = k;
        this.val = v;
    }

}
```
然后依靠我们的node类型构建一个双链表，实现几个需要的API：

```java
class DoubleList {
   // 头尾虚节点
   private Node head, tail;
   // 链表元素数
   private int size;

   public DoubleList() {
       // 初始化双向链表的数据
       head = new Node(0, 0);
       tail = new Node(0, 0);
       head.next = tail;
       tail.prev = head;
       size = 0;
   } 
   // 在链表头部添加节点 x，时间 O(1)
   public void addFirst(Node x) {
       x.next = head.next;
       x.prev = head;
       head.next.prev = x;
       head.next = x;
       size++;
   }
   //在链表尾部添加一个节点x时间复杂度为O(1)
   public void addLast(Node x) {
       x.prev = tail.prev;
       x.next = tail;
       tail.prev.next = x;
       tail.prev = x;
       size++;
   }
   //删除链表中的x节点（x一定存在）
   //由于是双链表且给的是目标Node节点，时间O(1)
   public void remove(Node x) {
       x.prev.next = x.next;
       x.next.prev = x.prev;
       size--;
   }
   //删除链表中第一个节点，并返回该节点，时间O(1)
   public Node removeFirst() {
       if(head.next == tail) {
           return null;
       }
       Node first = head.next;
       remove(first);
       return first;
   }
   //返回链表长度，时间O(1)
   public int size() {
    return size;  
   }

}
```
到这里就能回答为什么必须要用双向链表了，因为我们需要删除操作。删除一个节点不光要得到该节点本身的指针，也需要操作其前驱节点的指针，而双向链表才能支持直接查找前驱，保证操作的时间复杂度O(1)。

注意：我们实现的双链表API只能从尾部插入，也就是说靠尾部的数据式最近使用的，靠头部的数据式最久未使用的

有了双向链表的实现，我们只需要在LRU算法中把它和哈希表结合起来即可。我们先把逻辑理清楚：

```java
class LRUCache {
  // key -> Node(key, val)
  private HashMap<Integer, Node> map;
  // Node(k1, v1) <-> Node(k2, v2)...
  private DoubleList cache;
  // 最大容量
  private int cap;

  public LRUCache(int capacity) {
      this.cap = capacity;
      map = new HashMap<>();
      cache = new DoubleList();
  } 
}
```
先不着急去实现LRU算法的get和put方法。先搞清楚它的逻辑：由于要同时维护一个双链表cache和一个哈希表map，很容易漏掉一些操作，比如说删除某个key时，在cache中删除了对应的Node，但是却忘记在map中删除key。

解决这种问题的有效方法是：在这两种数据结构之上提供一层抽象API。

实际上就是尽量让LRU的主方法get和put避免直接操作map和cache的细节

```java
// 将某个key提升为最近使用的
private void makeRecently(int key) {
 Node x = map.get(key);
 // 先从链表中删除这个节点
 cache.remove(x);
 // 重新插到队尾
 cache.addLast(x); 
}
//添加最近使用的元素
private void addRecently(int key, int val) {
 Node x = new Node(key, val);
 // 链表尾部就是最近使用的元素
 cache.addLast(x);
 // 在map中添加key的映射
 map.put(key, x); 
}
//删除某一个key
private void deleteKey(int key) {
Node x = map.get(key);
// 从链表中删除
cache.remove(x);
// 从map中删除
map.remove(key); 
}
//删除最久未使用的元素
private void removeLeastRecently() {
// 链表头部的第一个元素就是最久未使用的
Node deletedNode = cache.removeFirst();
// 同时别忘了从map中删除它的key
int deletedKey = deletedNode.key;
map.remove(deletedKey);
}
```
这里就能回答为什么要在链表当中同时存储key和val，而不是只存储val，注意,在removeLeastRecently中，我们需要用deletedNode得到deletedKey。

也就是说，当缓存容量已满，我们不仅仅要删除最后一个Node节点，还要把map中映射到该节点的key同时删除，而这个key只能由Node得到。如果Node结构中只存储val，那么我们就无法得知key是什么，就无法删除map中的键，造成错误。

上述方法就是最简单的操作封装

调用这些函数可以避免直接操作cache链表和map哈希表，

```java
public int get(int key) {
    if(!map.containsKey(key)) {
        return -1;
    }
    // 将该数据提升为最近使用的
    makeRecently(key);
    return map.get(key).val;
}
```
这样就可以轻松写出put方法的代码了

```java
public void put(int key, int val) {
    if(map.containsKey(key)) {
        // 删除旧的数据
        deleteKey(key);
        // 新插入的数据为最近使用的数据
        addRecently(key, val);
        return;
    }
    if(cap == cache.size()) {
        // 删除最久未使用的元素
        removeLeastRecently();
    }
    // 添加为最近使用的元素
    addRecently(key, val);
}
```
至此，你应该已经完全掌握LRU算法的原理和实现了。最后用Java内置类型LinkedHashMap来实现LRU算法，逻辑和之前完全一致，这里就不过多解释了

```java
class LRUCache {
    int cap;
    LinkedHashMap<Integer, Integer> cache = new LinkedHashMap<>();
    public LRUCache(int capacity) {
        this.cap = capacity;
    }

    public int get(int key) {
        if(!cache.containsKey(key)) {
            return -1;
        }
        // 将key变为最近使用
        makeRecently(key);
        return cache.get(key);
    }
    public void put(int key, int val) {
        if(cache.containsKey(key)) {
            // 修改key的值
            cache.put(key, val);
            // 将key变为最近使用
            makeRecently(key);
            return;
        }
        if(cache.size() >= this.cap) {
            // 链表头部就是最久未使用的key
            int oldestKey = cache.keySet().iterator().next();
            cache.remove(oldestKey);
        }
        // 将新的key添加链表尾部
        cache.put(key, val);
    }
    private void makeRecently(int key) {
        int val = cache.get(key);
        // 删除key，重新插入到队尾
        cache.remove(key);
        cache.put(key, val);
    }
}
```

# 2.2.2带你手写LFU算法

LRU算法的淘汰策略式Least Recently Used，也就是最近最少使用，它认为最近使用过的数据应该是是「有用的」，很久都没用过的数据应该是无用的，内存满了就优先删那些很久没用过的数据。

LFU算法的淘汰策略是Least Frequently Used，也就是最近使用次数最少的数据，它认为如果数据过去被访问多次，那么将来被访问的频率也更高。

LRU算法的核心数据结构式使用哈希链表LinkedHashMap，首先借助链表的有序性使得链表元素维护插入顺序，同时借助哈希映射的快速访问能力使得我们可以以O1的时间复杂度访问链表的任意元素。

LFU算法的核心数据结构是使用双哈希链表，首先第一个哈希链表用来存储相同频次的元素，第二个哈希链表用来存储相同频次的元素的插入顺序。

从实现难度上来说，LRU算法的难度大于LRU算法，因为LRU算法相当于把数据按照时间排序，这个需求借助链表很自然就能实现的，一直从链表头部加入元素的话，越靠近头部的元素就是月薪的，越靠近尾部的元素就是越旧的数据的，进行缓存数据的淘汰的时候，只要简单的讲尾部的元素淘汰掉了就好了


LRU算法相当于把数据按照访问频次进行排序的，这个需求恐怕没有那么简单，如果多个数据拥有相同的访问频次，就应该删除最早插入的那个数据的，也就是说LFU算法就是淘汰访问频次最低的数据的，如果访问频次最低的数据有多条，需要淘汰最旧的数据的

那么本节就来带你拆解LFU算法，自顶向下，逐步求精，就是解决复杂问题的不二法门


要求你写一个类，接受一个capacity参数，实现get和put方法

```java
class LFUCache {
    // 构造容量未capacity的缓存;
    public LFUCache(int capacity) {}
    // 在缓存中查询key;
    public int get(int key) {}
    // 将key和val存入缓存;
    public void put(int key, int val) {}
}
```
get(key)方法会去缓存当中查找键key，如果key存在，则返回key对应的val，否则返回-1

put(key, val)方法插入或修改缓存。如果key已存在，则将它对应的值改为val；如果key不存在，则插入键值对(key, val)。

当缓存达到容量capacity时，则应该在插入新的键值对之前，删除使用频次（后文用freq表示）最低的键值对。如果freq最低的键值对有多个，则删除其中最旧的那一个。


当缓存达到容量capacty的时候，旧应该在插入新的键值对之前，删除使用频次最低的键值对，如果freq最低的键值对有多个，则删除最旧的那个

```java
//构造一个容量为2的LFU缓存
LFUCache cache = new LFUCache(2);
//插入两对（key, val），对应的freq都为1
cache.put(1, 10);
cache.put(2, 20);
//key为1的键值对，对应的freq变成2
cache.get(1);
//查询key为1对应的val
//返回10，同时键1对应的freq变成2
cache.get(1);
//插入一对（key, val），对应的freq为1
//因为容量已满，移除freq最低的键值对，也就是键2
cache.put(3, 30);
//返回-1，因为键2被移除了
cache.get(2);
```
### 思路分析

一定从最简单的开始，根据LFU算法的逻辑，我们先明确LFU算法的核心数据结构是什么


1.调用get(key)方法时，要返回该key对应的val

2.只要用get或者put方法访问一次某个key，该key的freq就要加1

3.如果在容量满了的情况下调用put方法，需要将freq最小的key删除，如果最小的freq对应多个key，删除其中最旧的那一个

好的，我们希望能够在o(1)的时间内解决这些需求，可以使用基本数据结构来逐个击破

1.首先，肯定是需要k，v键值对把数据存起来，只要k不重复，就可以用一个哈希表来存；

2.其次，需要用某个数据结构快速找到freq最小的key，然后移除对应的k，v；

3.希望能够快速删除freq最小的key，以及快速插入freq最小的key；

4.希望能够快速删除任意一个key，因为只要调用一次get或者put方法，这个key对应的freq就要加1；

5.希望能够快速找到key对应的freq，以便任何时候更新freq；


1。使用一个HashMap存储key到val的映射，就可以快速计算get(key)；

```js
HashMap<Integer, Integer> keyToVal;
```

2。使用一个HashMap存储key到freq的映射，就可以快速操作key对应的freq；

```java
HashMap<Integer, Integer> keyToFreq;
```

3。这个需求应该是LFU算法的核心，所以我们分开说。

3.1首先，肯定是需要freq到key的映射，用来寻找freq最小的key。

3.2将freq最小的key删除，那你就得快速得到当前所有key最小的freq是多少。

想要时间复杂度O(1)的话，肯定不能遍历一遍去找，那就用一个变量minFreq来记录当前最小的freq吧。

3.3也许你会问，那如果一个freq对应的key有多个，你怎么对应着删除key呢？

3.4希望freq对应的key的列表是存在时序的，便于快速查找并删除最旧的key的

3.5希望能够快速删除key列表中的任何一个key，因为如果频次为freq的某个key被访问，那么它的频次就会变成freq+1，就应该从freq对应的key列表中删除，加到freq+1对应的key的列表中

```js
HashMap<Integer, LinkedHashSet<Integer>> freqToKeys;
int minFreq = 0;
```

介绍一下这个LinkedHashSet，它满足，但是由于普通链表不能快速访问链表当中的某一个节点，所以无法满足3.5要求的

类似上一届介绍的LinkedHashMap，LinkedHashSet作为哈希集合，不仅提供了常数时间的添加，删除和查询操作，还记录了元素插入的先后顺序，即迭代器将会按照元素的插入顺序进行迭代

那么，他俩结合起来就兼具了哈希集合和链表的特性，不仅可以在O（1）时间内实现哈希集合的基本操作，还可以记录键值对的插入顺序，将get最近使用的元素放到链表的尾部，并且保证链表元素的顺序是插入顺序，这样我们就可以快速的找到最近最少使用的键值对了

```java
class LFUCache {
    // key 到 val 的映射，我们后文称为 KV 表
    HashMap<Integer, Integer> keyToVal;
    // key 到 freq 的映射，我们后文称为 KF 表
    HashMap<Integer, Integer> keyToFreq;
    // freq 到 key 列表的映射，我们后文称为 FK 表
    HashMap<Integer, LinkedHashSet<Integer>> freqToKeys;
    // 记录最小的频次
    int minFreq;
    // 记录 LFU 缓存的最大容量
    int cap;

    public LFUCache(int capacity) {
        keyToVal = new HashMap<>();
        keyToFreq = new HashMap<>();
        freqToKeys = new HashMap<>();
        this.cap = capacity;
        this.minFreq = 0;
    }

    public int get(int key) {
     
    }
    public void put(int key, int val) {
     
    }
}
```

## 代码框架

LFU的逻辑不难理解，因为要维护KV表，KF表和FK表三个映射，特别容易出错，对于这种情况，

1.不要企图上来就实现算法的所有细节，而应该自顶向下，逐步求精，先写清楚主函数的逻辑框架，然后再一步步实现细节

2. 搞清楚映射关系，如果我们更新了某个key对应的freq，那么我们就要同步修改KF表和FK表，这样才不会出问题

3.画图，画图，画图，重要的话要说三遍，把逻辑比较复杂的部分用流程图画出来，然后根据图来写代码，可以极大降低出错的概率

下面我们来实现get(key)的方法，逻辑很简单，返回key对应的val，然后增加key对应的dreq

```java
public int get(int key) {
    if (!keyToVal.containsKey(key)) {
        return -1;
    }
    // 增加 key 对应的 freq
    increaseFreq(key);
    return keyToVal.get(key);
}
```

下面我们来实现put(key, val)的方法，逻辑也不难，先看key是否存在

1.key存在，修改对应的val，然后增加key对应的freq

2.key不存在，需要插入key和val，插入key和val，就要先判断是否达到容量cap

2.1 达到容量，需要淘汰一个freq最小的key，然后再插入key和val
2.2没有达到容量，直接插入key和val

这里就直接写代码了，逻辑很简单，把刚才的逻辑翻译成代码即可

```java
public void put(int key, int val) {
    if (cap <= 0) return;

    /* 若 key 已存在，修改对应的 val 即可 */
    if (keyToVal.containsKey(key)) {
        keyToVal.put(key, val);
        // key 对应的 freq 加一
        increaseFreq(key);
        return;
    }
    /* key 不存在，需要插入 */
    /* 容量已满的话需要淘汰一个 freq 最小的 key */
    if (keyToVal.size() >= cap) {
        removeMinFreqKey();
    }

    /* 插入 key 和 val，对应的 freq 为 1 *  /
    // 插入 KV 表
    keyToVal.put(key, val);
    // 插入 KF 表
    keyToFreq.put(key, 1);
    // 插入 FK 表
    freqToKeys.putIfAbsent(1, new LinkedHashSet<>());
    freqToKeys.get(1).add(key);
    // 插入新 key 后最小的 freq 肯定是 1
    minFreq = 1;
}
```
increaseFreq和removeMinFreqKey这两个函数是LFU算法的核心，逻辑很简单，但是读者可以和之前的例子类比，看看如何修改。
### LFU核心逻辑

首先实现removeMinFreqKey函数

```java
private void removeMinFreqKey() {
    // freq 最小的 key 列表
    LinkedHashSet<Integer> keyList = freqToKeys.get(minFreq);
    // 其中最先被插入的那个 key 就是该被淘汰的 key
    int deletedKey = keyList.iterator().next();
    /* 更新 FK 表 */
    keyList.remove(deletedKey);
    if (keyList.isEmpty()) {
        freqToKeys.remove(minFreq);
        // 问：这里需要更新 minFreq 的值吗？
    }
    /* 更新 KV 表 */
    keyToVal.remove(deletedKey);
    /* 更新 KF 表 */
    keyToFreq.remove(deletedKey);
}
```
删除某个键key肯定要同时删除三个映射表的，借助minFreq参数可以从FK表当中找到freq最少的keyList的，根据时序，其中第一个元素就是要淘汰deletedKey，

操作三个映射表删除这个key就可以了


下面来实现increaseFreq函数

```java
private void increaseFreq(int key) {
    int freq = keyToFreq.get(key);
    /* 更新 KF 表 */
    keyToFreq.put(key, freq + 1);
    /* 更新 FK 表 */
    // 将 key 从 freq 对应的列表中删除
    freqToKeys.get(freq).remove(key);
    // 将 key 加入 freq + 1 对应的列表中
    freqToKeys.putIfAbsent(freq + 1, new LinkedHashSet<>());
    freqToKeys.get(freq + 1).add(key);
    // 如果 freq 对应的列表空了，移除这个 freq
    if (freqToKeys.get(freq).isEmpty()) {
        freqToKeys.remove(freq);
        // 如果这个 freq 恰好是 minFreq，更新 minFreq
        if (freq == minFreq) {
            minFreq++;
        }
    }
}
```

更新某个key的freq肯定会设计FK表和KF表的，所以我们分别更新这两个表了

和之前类似，当FK表当中的freq对应的列表被删除空以后，需要删除FK表当中的freq这个映射的，

## 2.2.3以O1的时间复杂度删除/查找数组当总的任意的元素

本节讲两道有技巧性的数据结构设计题，都是和随机读取元素相关的，这些问题的一个技巧点在于，如何结合哈希表和数组，使得数组的删除操作时间复杂纛也变成O(1)

## 1.实现随机集合

这是力扣第380题O(1)时间插入、删除和获取随机元素，就是让我们实现如下这个类，并且其中的三个方法的时间复杂度都必须是O(1)

```java
class RandomizedSet {
    public boolean insert(int val) {}
    public boolean remove(int val) {}
    public int getRandom() {}
}
```

本体的难点在于：

1.插入·删除·获取随即元素这三个操作的时间复杂度必须是O(1)

2.getRandom方法返回的元素必须是等概率返回的

对于等概率返回，也就是说，如果集合里面有n个元素，每个元素被返回的概率必须是1/n

那么我们首先来分析一下：对于数组实现，插入，删除，查找这几个操作，时间复杂度是多少呢？

HashSet(哈希集合)肯定算是一个，哈希集合的底层原理就是一个大数组的，我们把元素通过哈希函数映射到一个索引上的，如果用拉链法解决哈希冲突，那么这个索引可能连着一个链表或者红黑树的

哈希表配合双链表，元素存储在双链表当中，但是linkedhashset只是给hashset增加了有序性，依然无法接受按照要求实现我们的getRandom函数的，因为底层链表结构存储元素的话，是无法在O(1)时间内访问某一个元素的

所以对于数组实现，插入，删除，查找这几个操作，时间复杂度是多少呢？

数组肯定是不行的，因为数组的插入，删除，按照索引访问这些操作，时间复杂度都是O(1)，但是如果我们想在数组当中按照某个元素值进行查找，还得遍历数组，时间复杂度为O(
N)

底层用数组存储元素，并且数组必须是紧凑的

这样就可以直接生成随机数作为索引，从书中当中去除改随机索引对应的元素，作为随机元素的


如果想要在O(1)的时间删除数组中的某一个元素val，可以先把这个元素交换到数组的尾部，然后再pop掉

这样就可以避免数据空洞的出现，多次删除操作后，尾部就会出现空洞，但是如果我们在数组中插入元素的话，就有可能会插入到尾部的空洞当中，这样的话，我们就需要在插入之前进行处理了

交换两个元素必须通过索引进行交换的，那么需要一个哈希表valToIndex来记录每个元素值对应的索引

这样，我们可以通过val快速得到这个元素在数组中的索引，然后进行交换操作，之后再pop掉即可，交换的时间复杂度是O(1)，pop的时间复杂度也是O(1)，所以总的时间复杂度还是O(1)

```java
class RandomizedSet {
public:
    //存储元素的只
    vector<int> nums;
    //记录每个元素对应在nums中的索引
    unordered_map<int, int> valToIndex;
    bool insert(int val) {
        //若val已存在，不用再插入
        if (valToIndex.count(val)) {
            return false;
        }
        //若val不存在，插入到nums尾部，
        //并记录val对应的索引值
        valToIndex[val] = nums.size();
        nums.push_back(val);
        return true;
    }
    bool remove(int val) {
        //若val不存在，不用再删除
        if (!valToIndex.count(val)) {
            return false;
        }
        //先拿到val的索引
        int index = valToIndex[val];
        //将最后一个元素对应的索引修改为index
        valToIndex[nums.back()] = index;
        //交换val和最后一个元素
        swap(nums[index], nums.back());
        //在数组中删除元素val
        nums.pop_back();
        //删除元素val对应的索引
        valToIndex.erase(val);
        return true;
    }
    int getRandom() {
        //随机获取nums中的一个元素
        return nums[rand() % nums.size()];
    }
}
```
注意remove(vqal)函数，对nums进行插入删除和交换的时候，都要记得修改哈希表valToIndex，否则会出现错误，

至此每道题的复杂度都是O(1)，并且随机抽取元素的概率都是相等的
